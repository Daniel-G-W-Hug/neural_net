# (number of nodes per layer; number>0 for each layer)
2, 1
# activation function for hidden layers (int):
# (identity=1, sigmoid=2, tanhyp=3, reLU=4, leaky_reLU=5)
2
# activation function for output layer (int):
# (identity=1, sigmoid=2, tanhyp=3, reLU=4, leaky_reLU=5)
2
# max. number of iteration over the whole data set (int, epochmax):
1000
# limit output to every nth iteration in each epoch (int):
# (epoch_output_skip, such that epoch%epoch_output_skip == 0):
10
# learning_rate for gradient descent (double):
0.1
# minimum loss in training to stop prescribed interation,
# even if epoch < epochmax (int):
# (min_target_loss)
0.001
# minimum relative loss change rate per epoch in training to stop prescribed interation,
# even if epoch < epochmax (int):
# (min_relative_loss_change_rate)
1.e-7
# update strategy either after each training pair or after batch of training pairs (int):
# (immediate_update = 1, batch_update = 2)
1