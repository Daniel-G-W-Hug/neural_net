{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,28*28)\n",
    "x_test=x_test.reshape(10000,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(50, activation=\"relu\", name=\"hidden\"),\n",
    "        #layers.Dense(10, name=\"output\"),\n",
    "        layers.Dense(10, activation=\"softmax\", name=\"output\"),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.9086824e-20, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 5.6088512e-38, ..., 4.1709968e-13,\n",
       "        6.8112215e-15, 3.3048114e-26],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.7118847e-02, 1.5578597e-28],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(60000, 784)\n",
      "(10000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (10000, 50)               39250     \n",
      "                                                                 \n",
      " output (Dense)              (10000, 10)               510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39760 (155.31 KB)\n",
      "Trainable params: 39760 (155.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 10.0567 - accuracy: 0.7290 - val_loss: 1.5949 - val_accuracy: 0.7673\n",
      "Epoch 2/30\n",
      "211/211 [==============================] - 0s 985us/step - loss: 1.2322 - accuracy: 0.7560 - val_loss: 0.8506 - val_accuracy: 0.8017\n",
      "Epoch 3/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.8146 - accuracy: 0.8058 - val_loss: 0.6621 - val_accuracy: 0.8472\n",
      "Epoch 4/30\n",
      "211/211 [==============================] - 0s 999us/step - loss: 0.6422 - accuracy: 0.8423 - val_loss: 0.5526 - val_accuracy: 0.8703\n",
      "Epoch 5/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8679 - val_loss: 0.4841 - val_accuracy: 0.8938\n",
      "Epoch 6/30\n",
      "211/211 [==============================] - 0s 998us/step - loss: 0.4410 - accuracy: 0.8846 - val_loss: 0.4482 - val_accuracy: 0.9028\n",
      "Epoch 7/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8984 - val_loss: 0.4020 - val_accuracy: 0.9140\n",
      "Epoch 8/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.9077 - val_loss: 0.3848 - val_accuracy: 0.9198\n",
      "Epoch 9/30\n",
      "211/211 [==============================] - 0s 999us/step - loss: 0.3082 - accuracy: 0.9172 - val_loss: 0.3550 - val_accuracy: 0.9242\n",
      "Epoch 10/30\n",
      "211/211 [==============================] - 0s 996us/step - loss: 0.2773 - accuracy: 0.9230 - val_loss: 0.3435 - val_accuracy: 0.9273\n",
      "Epoch 11/30\n",
      "211/211 [==============================] - 0s 994us/step - loss: 0.2573 - accuracy: 0.9286 - val_loss: 0.3310 - val_accuracy: 0.9335\n",
      "Epoch 12/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9335 - val_loss: 0.3329 - val_accuracy: 0.9360\n",
      "Epoch 13/30\n",
      "211/211 [==============================] - 0s 997us/step - loss: 0.2166 - accuracy: 0.9371 - val_loss: 0.2867 - val_accuracy: 0.9373\n",
      "Epoch 14/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9408 - val_loss: 0.3069 - val_accuracy: 0.9360\n",
      "Epoch 15/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9441 - val_loss: 0.2784 - val_accuracy: 0.9405\n",
      "Epoch 16/30\n",
      "211/211 [==============================] - 0s 998us/step - loss: 0.1781 - accuracy: 0.9466 - val_loss: 0.3213 - val_accuracy: 0.9450\n",
      "Epoch 17/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9486 - val_loss: 0.3060 - val_accuracy: 0.9372\n",
      "Epoch 18/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9505 - val_loss: 0.2806 - val_accuracy: 0.9483\n",
      "Epoch 19/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9537 - val_loss: 0.2536 - val_accuracy: 0.9488\n",
      "Epoch 20/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9541 - val_loss: 0.2483 - val_accuracy: 0.9472\n",
      "Epoch 21/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9567 - val_loss: 0.2804 - val_accuracy: 0.9448\n",
      "Epoch 22/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9571 - val_loss: 0.2595 - val_accuracy: 0.9492\n",
      "Epoch 23/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9574 - val_loss: 0.2692 - val_accuracy: 0.9488\n",
      "Epoch 24/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9588 - val_loss: 0.2546 - val_accuracy: 0.9508\n",
      "Epoch 25/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9608 - val_loss: 0.2549 - val_accuracy: 0.9508\n",
      "Epoch 26/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9612 - val_loss: 0.2773 - val_accuracy: 0.9512\n",
      "Epoch 27/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9628 - val_loss: 0.2433 - val_accuracy: 0.9518\n",
      "Epoch 28/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9639 - val_loss: 0.2351 - val_accuracy: 0.9532\n",
      "Epoch 29/30\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9646 - val_loss: 0.2115 - val_accuracy: 0.9562\n",
      "Epoch 30/30\n",
      "211/211 [==============================] - 0s 999us/step - loss: 0.1102 - accuracy: 0.9666 - val_loss: 0.2310 - val_accuracy: 0.9525\n",
      "Test loss: 0.3185455799102783\n",
      "Test accuracy: 0.9452000260353088\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "batch_size=256\n",
    "epochs=30\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adagrad\", metrics=[\"accuracy\"])\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
